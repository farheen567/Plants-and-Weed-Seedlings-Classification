{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45804db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad215de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['Black-grass',\n",
    "          'Charlock',\n",
    "          'Cleavers',\n",
    "          'Common Chickweed',\n",
    "          'Common wheat',\n",
    "          'Fat Hen',\n",
    "          'Loose Silky-bent',\n",
    "          'Maize',\n",
    "          'Scentless Mayweed',\n",
    "          'Shepherds Purse',\n",
    "          'Small-flowered Cranesbill',\n",
    "          'Sugar beet']\n",
    "\n",
    "IMG_SIZE=224\n",
    "\n",
    "DATADIR  = 'D:/project/dataset/train'\n",
    "DATADIR_TEST  = 'D:/project/dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = DATADIR\n",
    "batch_size = 16\n",
    "# create data generators\n",
    "def data_generators():\n",
    "\n",
    "    # apply random transformations on training data\n",
    "    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        validation_split = 0.1,\n",
    "    )\n",
    "    test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rescale=1./255)\n",
    "    \n",
    "    train_gen = train_data_generator.flow_from_directory(\n",
    "        directory = TRAIN_DATA_DIR,\n",
    "        target_size = (IMG_SIZE, IMG_SIZE),\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = \"categorical\",\n",
    "        batch_size = batch_size,\n",
    "        subset = 'training',\n",
    "    )\n",
    "\n",
    "    # define validation data generator\n",
    "    validation_gen = train_data_generator.flow_from_directory(\n",
    "        directory = TRAIN_DATA_DIR,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = \"categorical\",\n",
    "        target_size = (IMG_SIZE, IMG_SIZE),\n",
    "        batch_size = batch_size,\n",
    "        subset = 'validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_gen = test_data_generator.flow_from_directory(\n",
    "        directory= 'D:/project/dataset',\n",
    "        classes=['test'],\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=1,\n",
    "        color_mode='rgb',\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "    return train_gen, validation_gen, test_gen\n",
    "train_gen, validation_gen, test_gen = data_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Sequential\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=(3,3), input_shape=(width, height, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1)) #dropout for each layer in order to avoid overfitting.\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128,kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f94e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= optimizer ,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model regularly\n",
    "save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath = 'best.h5',monitor = 'val_accuracy', \n",
    "                                                     save_best_only = True, verbose = 1,mode='max')\n",
    "# reduce learning rate when it stops decreasing\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4,patience = 3,\n",
    "                                                 min_lr = 1e-10, verbose = 1, cooldown = 1)\n",
    "# stop training early if no further improvement\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta = 1e-2, patience = 10, verbose = 1,\n",
    "        mode = 'max', baseline = None, restore_best_weights = True)\n",
    "callback=[save_best_model, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = resnet_model.fit(train_gen,\n",
    "          epochs = 100,\n",
    "          steps_per_epoch=train_gen.samples // batch_size,\n",
    "          validation_data = validation_gen,\n",
    "          validation_steps = validation_gen.samples // batch_size,\n",
    "          callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_generator( validation_gen, validation_gen.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_gen.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(validation_gen.classes, y_pred, target_names=CATEGORIES))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
